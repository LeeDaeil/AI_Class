{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# 5. RNN 계열의 네트워크를 사용한 시계열 데이터 처리\n",
    "## 5.1 데이터 로드와 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read (52, 120700, 75).csv \t train_x shape : (117, 3, 2) train_y shape : (117,)\n",
      "Read (12, 100010, 50).csv \t train_x shape : (234, 3, 2) train_y shape : (234,)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import os\n",
    "from collections import deque\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "train_x, train_y = np.array([]), np.array([])\n",
    "train_x_seq, train_y_seq = np.array([[]]), np.array([])\n",
    "\n",
    "want_para = ['WAFWTK', 'FCWP']\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "for file in os.listdir('./DB')[0:2]:\n",
    "    time_seq = 3\n",
    "    if '.csv' in file:\n",
    "        csv_db = pd.read_csv(f'./DB/{file}', index_col=0)\n",
    "        #1. CSV 파일을 Numpy 배열로 전환\n",
    "        get_xdb = csv_db[want_para].to_numpy()\n",
    "\n",
    "        #2. 라벨링\n",
    "        get_ydb = csv_db.loc[:, 'Normal_0'].to_numpy()\n",
    "        accident_nub = {\n",
    "            '12': 1, # LOCA\n",
    "            '13': 2, # SGTR\n",
    "            '15': 1, # PZR PORV [LOCA]\n",
    "            '17': 1, # Feedwater line leak [LOCA]\n",
    "            '18': 3, # Steam Line Rupture MSLB\n",
    "            '52': 3, # Steam Line Rupture MSLB (non-isolable)\n",
    "        }\n",
    "        get_mal_nub = file.split(',')[0][1:] # '(12, 000000, 10)' -> 12\n",
    "        get_y = np.where(get_ydb != 0, accident_nub[get_mal_nub], get_ydb)\n",
    "\n",
    "        #3. 데이터 축적\n",
    "        train_x = get_xdb if train_x.shape[0] == 0 else np.concatenate((train_x, get_xdb), axis=0)\n",
    "        train_y = np.append(train_y, get_y, axis=0)\n",
    "\n",
    "        if time_seq != 1:\n",
    "            for i in range(len(get_xdb) - time_seq - 1):\n",
    "                # print(get_xdb[i:i + time_seq], get_y[i + time_seq + 1])\n",
    "                x__ = np.array([get_xdb[i:i + time_seq]])\n",
    "                train_x_seq = x__ if train_x_seq.shape[1] == 0 else np.concatenate((train_x_seq, np.array([get_xdb[i:i + time_seq]])), axis=0)\n",
    "\n",
    "                y__ = np.array([get_y[i + time_seq + 1]])\n",
    "                train_y_seq = y__ if train_y_seq.shape[0] == 0 else np.concatenate((train_y_seq, y__), axis=0)\n",
    "\n",
    "        #4. min_max scaler update\n",
    "        scaler.partial_fit(train_x)\n",
    "\n",
    "        if time_seq != 1:\n",
    "            print(f'Read {file} \\t train_x shape : {np.shape(train_x_seq)} train_y shape : {np.shape(train_y_seq)}')\n",
    "        else:\n",
    "            print(f'Read {file} \\t train_x shape : {np.shape(train_x)} train_y shape : {np.shape(train_y)}')\n",
    "\n",
    "# 5. 전체 db min-max scaling\n",
    "train_x_seq = np.array([scaler.transform(_) for _ in train_x_seq])\n",
    "\n",
    "# 6. 저장\n",
    "save_data_info = {\n",
    "    'scaler': scaler,\n",
    "    'want_para': want_para,\n",
    "    'time_seq': time_seq,\n",
    "    'train_x': train_x_seq,\n",
    "    'train_y': train_y_seq,\n",
    "}\n",
    "\n",
    "with open('db_info.pkl', 'wb') as f:\n",
    "    pickle.dump(save_data_info, f)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 4. 훈련데이터 불러오기 및 네트워크 훈련\n",
    "## 4.1 훈련데이터 불러오기"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "with open('db_info.pkl', 'rb') as f:\n",
    "    save_data_info = pickle.load(f)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3.2 네트워크 빌드 및 훈련"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "rnn (RNN)                    (None, 32)                1120      \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 128)               4224      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 4)                 516       \n",
      "=================================================================\n",
      "Total params: 5,860\n",
      "Trainable params: 5,860\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/5\n",
      "8/8 [==============================] - 2s 12ms/step - loss: 1.3497 - accuracy: 0.3401\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 2/5\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 1.0744 - accuracy: 0.5202\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 3/5\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.9327 - accuracy: 0.5894\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 4/5\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.8087 - accuracy: 0.6179\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 5/5\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.8085 - accuracy: 0.6211\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n"
     ]
    },
    {
     "data": {
      "text/plain": "<tensorflow.python.keras.callbacks.History at 0x21f85604eb0>"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow.keras as k\n",
    "\n",
    "model = k.Sequential([\n",
    "    # k.layers.RNN(k.layers.SimpleRNNCell(32), input_shape=(save_data_info['time_seq'], len(save_data_info['want_para']))),\n",
    "    k.layers.RNN(k.layers.SimpleRNNCell(32), input_shape=(save_data_info['time_seq'], len(save_data_info['want_para']))),\n",
    "    k.layers.Flatten(),\n",
    "    k.layers.Dense(128, activation='relu'),\n",
    "    k.layers.Dense(4, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "print(model.summary())\n",
    "model.fit(save_data_info['train_x'], save_data_info['train_y'], epochs=5)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3.3 네트워크 저장"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "model.save_weights('model.h5')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3.4 네트워크 로드"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model.load_weights('model.h5')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}